{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dirty-preservation",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import random\n",
    "import math\n",
    "import numpy as np\n",
    "import nibabel as nib\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import cv2\n",
    "from PIL import Image\n",
    "\n",
    "from tqdm import tqdm\n",
    "import skimage\n",
    "from skimage.metrics import peak_signal_noise_ratio, structural_similarity\n",
    "from skimage.io import imread\n",
    "from skimage.transform import pyramid_reduce, resize\n",
    "from scipy.ndimage import zoom\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.layers import Input, Activation, Conv2D, Flatten, Dense, MaxPooling2D, Dropout, Add, LeakyReLU, UpSampling2D, Conv2DTranspose, Concatenate, BatchNormalization\n",
    "from tensorflow.keras.models import Model, load_model\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.transforms import ToTensor\n",
    "from torch.autograd import Variable\n",
    "\n",
    "\n",
    "from tensorflow.python.client import device_lib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "durable-facility",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_img(path):\n",
    "    img = Image.open(path)\n",
    "    img = np.array(img)\n",
    "    print(img.shape)\n",
    "    H,W,D = img.shape\n",
    "    \n",
    "    video = np.zeros((2, H, W, D), dtype = np.float32)\n",
    "    video[0] = img\n",
    "    return video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ongoing-local",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepro(video) :\n",
    "    \n",
    "    resize_video = np.zeros((len(video), 256, 256, 1), dtype = np.float32)\n",
    "\n",
    "    for i, img in enumerate(video):\n",
    "        resize_video[i] = resize(img, output_shape=(256, 256, 1), preserve_range=True)\n",
    "        \n",
    "    max_num = 0\n",
    "    for j, image in enumerate(resize_video) :\n",
    "        max_num = np.max(image)\n",
    "        \n",
    "        if(np.abs(image.min()) > max_num) :\n",
    "            max_num = np.abs(image.min())\n",
    "            \n",
    "        if(max_num != 0) :\n",
    "            image = image / max_num\n",
    "        \n",
    "        if(np.min(image) < 0) :\n",
    "            image = image + 1\n",
    "            image = image / 2\n",
    "        \n",
    "        resize_video[j] = image\n",
    "        print('Number : ', j ,' min :', resize_video[j].min(),'max : ' ,resize_video[j].max())\n",
    "    return resize_video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "connected-violin",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_10(video):\n",
    "    print(video.shape)\n",
    "    fig, ax = plt.subplots(10, 1, figsize=(10, 100))\n",
    "    \n",
    "    temp = np.zeros((10,256, 256, 1), dtype=np.float32)\n",
    "    \n",
    "    for j,img in enumerate(video) :\n",
    "        if(j == 10) : break\n",
    "        temp[j] = img\n",
    "\n",
    "    for i in range(10):\n",
    "        ax[i].imshow(temp[i].squeeze())\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "unable-myrtle",
   "metadata": {},
   "outputs": [],
   "source": [
    "video = get_img(\"dataset/Test/test.jpg\")\n",
    "video = prepro(video)\n",
    "show_10(video)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "racial-literature",
   "metadata": {},
   "outputs": [],
   "source": [
    "#데이터 셋 가져오기\n",
    "def get_Segmentation_data():\n",
    "\n",
    "    x_train_path = \"dataset/Image_Segmentation/x_train2.npy\"\n",
    "    x_val_path = \"dataset/Image_Segmentation/x_val2.npy\" \n",
    "    y_train_path = \"dataset/Image_Segmentation/y_train2.npy\"\n",
    "    y_val_path = \"dataset/Image_Segmentation/y_val2.npy\"\n",
    "    \n",
    "    x_train = np.load(x_train_path)\n",
    "    x_val = np.load(x_val_path)\n",
    "    y_train = np.load(y_train_path)\n",
    "    y_val = np.load(y_val_path)\n",
    "\n",
    "    print(x_train.shape, y_train.shape)\n",
    "    print(x_val.shape, y_val.shape)\n",
    "    \n",
    "        \n",
    "    return x_train, y_train, x_val, y_val\n",
    "\n",
    "\n",
    "def get_Detection_data():\n",
    "\n",
    "    x_train_path = \"dataset/Infection/mask_infection.npy\"\n",
    "    x_val_path = \"dataset/Infection/mask_infection_val.npy\"\n",
    "    x_test_path = \"dataset/Infection/mask_infection_test.npy\"\n",
    "    y_train_path = \"dataset/Infection/y_train3.npy\"\n",
    "    y_val_path = \"dataset/Infection/y_val3.npy\"\n",
    "    y_test_path = \"dataset/Infection/y_test3.npy\"\n",
    "    \n",
    "    x_train = np.load(x_train_path)\n",
    "    x_val = np.load(x_val_path)\n",
    "    x_test = np.load(x_test_path)\n",
    "    y_train = np.load(y_train_path)\n",
    "    y_val = np.load(y_val_path)\n",
    "    y_test = np.load(y_test_path)\n",
    "\n",
    "    print(x_train.shape, y_train.shape)\n",
    "    print(x_val.shape, y_val.shape)\n",
    "    print(x_test.shape, y_test.shape)\n",
    "    \n",
    "        \n",
    "    return x_train, x_val, x_test, y_train, y_val, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "still-anchor",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CNN 인 VGG16 U-net\n",
    "def VGG16_Unet(x_train, y_train, x_val, y_val) :\n",
    "  \n",
    "    inputs = Input(shape=(256, 256, 1))\n",
    "\n",
    "    #down sampling \n",
    "    filters = 16       #feature map 수\n",
    "    kernel_size = 3    # kernel size\n",
    "    copy_layers = []   # Encoder에 있는 Activation map을 저장하는 리스트\n",
    "    net = inputs\n",
    "  \n",
    "    #Encoder1\n",
    "    net = Conv2D(filters, kernel_size, activation='relu', padding='same') (net)\n",
    "    net = Conv2D(filters, kernel_size, activation='relu', padding='same') (net)\n",
    "    net = BatchNormalization() (net)\n",
    "    copy_layers.append(net) #첫번째 Activation map 저장\n",
    "    net = MaxPooling2D((2, 2), strides=(2, 2)) (net)\n",
    "    filters = filters*2\n",
    "    \n",
    "    #Encoder2 \n",
    "    net = Conv2D(filters, kernel_size, activation='relu', padding='same') (net)\n",
    "    net = Conv2D(filters, kernel_size, activation='relu', padding='same') (net)\n",
    "    net = BatchNormalization() (net)\n",
    "    copy_layers.append(net) #두번째 Activation map 저장\n",
    "    net = MaxPooling2D((2, 2), strides=(2, 2)) (net)\n",
    "    filters = filters*2\n",
    "    \n",
    "    #Encoder3\n",
    "    net = Conv2D(filters, kernel_size, activation='relu', padding='same') (net)\n",
    "    net = Conv2D(filters, kernel_size, activation='relu', padding='same') (net)\n",
    "    net = Conv2D(filters, kernel_size, activation='relu', padding='same') (net)\n",
    "    net = BatchNormalization() (net)\n",
    "    copy_layers.append(net) #세번째 Activation map 저장\n",
    "    net = MaxPooling2D((2, 2), strides=(2, 2)) (net)\n",
    "    filters = filters*2\n",
    "    \n",
    "    #Encoder4\n",
    "    net = Conv2D(filters, kernel_size, activation='relu', padding='same') (net)\n",
    "    net = Conv2D(filters, kernel_size, activation='relu', padding='same') (net)\n",
    "    net = Conv2D(filters, kernel_size, activation='relu', padding='same') (net)\n",
    "    net = BatchNormalization() (net)\n",
    "    copy_layers.append(net) #네번째 Activation map 저장\n",
    "    net = MaxPooling2D((2, 2), strides=(2, 2)) (net)\n",
    "    \n",
    "    #Encoder5\n",
    "    net = Conv2D(filters, kernel_size, activation='relu', padding='same') (net)\n",
    "    net = Conv2D(filters, kernel_size, activation='relu', padding='same') (net)\n",
    "    net = Conv2D(filters, kernel_size, activation='relu', padding='same') (net)\n",
    "    net = BatchNormalization() (net)\n",
    "    copy_layers.append(net) #다섯번째 Activation map 저장\n",
    "    net = MaxPooling2D((2, 2), strides=(2, 2)) (net)\n",
    "    \n",
    "    #128\n",
    "    net = Conv2D(filters, kernel_size, activation='relu', padding='same') (net)\n",
    "    net = BatchNormalization() (net)\n",
    "    \n",
    "    \n",
    "    #Decoder : upsampling\n",
    "    j = len(copy_layers) - 1\n",
    "    net = Conv2DTranspose(filters, 2, strides=(2, 2), padding='same') (net)\n",
    "    net = Concatenate(axis=3)([net, copy_layers[j]]) #다섯번째 Activation map \n",
    "    \n",
    "    net = Conv2D(filters, kernel_size, activation='relu', padding='same') (net)\n",
    "    net = Conv2D(filters, kernel_size, activation='relu', padding='same') (net)\n",
    "    net = Conv2D(filters, kernel_size, activation='relu', padding='same') (net)\n",
    "    net = BatchNormalization() (net)\n",
    "    j = j -1 \n",
    "\n",
    "    net = Conv2DTranspose(filters, 2, strides=(2, 2), padding='same') (net)\n",
    "    net = Concatenate(axis=3)([net, copy_layers[j]]) #네번째 Activation map\n",
    "    net = Conv2D(filters, kernel_size, activation='relu', padding='same') (net)\n",
    "    net = Conv2D(filters, kernel_size, activation='relu', padding='same') (net)\n",
    "    net = Conv2D(filters, kernel_size, activation='relu', padding='same') (net)\n",
    "    net = BatchNormalization() (net)\n",
    "\n",
    "    filters = filters/2\n",
    "    j = j -1 \n",
    "    \n",
    "    net = Conv2DTranspose(filters, 2, strides=(2, 2), padding='same') (net)\n",
    "    net = Concatenate(axis=3)([net, copy_layers[j]]) #세번째 Activation map\n",
    "    net = Conv2D(filters, kernel_size, activation='relu', padding='same') (net)\n",
    "    net = Conv2D(filters, kernel_size, activation='relu', padding='same') (net)\n",
    "    net = Conv2D(filters, kernel_size, activation='relu', padding='same') (net)\n",
    "    net = BatchNormalization() (net)\n",
    "\n",
    "    filters = filters/2\n",
    "    j = j -1 \n",
    "    \n",
    "    net = Conv2DTranspose(filters, 2, strides=(2, 2), padding='same') (net)\n",
    "    net = Concatenate(axis=3)([net, copy_layers[j]]) #두번째 Activation map\n",
    "    net = Conv2D(filters, kernel_size, activation='relu', padding='same') (net)\n",
    "    net = Conv2D(filters, kernel_size, activation='relu', padding='same') (net)\n",
    "    net = Conv2D(filters, kernel_size, activation='relu', padding='same') (net)\n",
    "    net = BatchNormalization() (net)\n",
    "    \n",
    "    filters = filters/2\n",
    "    j = j -1 \n",
    "    \n",
    "    net = Conv2DTranspose(filters, 2, strides=(2, 2), padding='same') (net)\n",
    "    net = Concatenate(axis=3)([net, copy_layers[j]]) #첫번째 Activation map\n",
    "    net = Conv2D(filters, kernel_size, activation='relu', padding='same') (net)\n",
    "    net = Conv2D(filters, kernel_size, activation='relu', padding='same') (net)\n",
    "    net = Conv2D(filters, kernel_size, activation='relu', padding='same') (net)\n",
    "    net = BatchNormalization() (net)\n",
    "    \n",
    "    outputs = Conv2D(2, 1, activation='sigmoid') (net)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    model = Model(inputs=inputs, outputs=outputs)\n",
    "\n",
    "    model.compile(optimizer='rmsprop', loss='binary_crossentropy', \n",
    "                  metrics=['acc',tf.keras.metrics.MeanIoU(num_classes=2)])\n",
    "\n",
    "    model.summary()\n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "documentary-third",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Unet(x_train, y_train, x_val, y_val) :\n",
    "    \n",
    "    inputs = Input(shape=(256, 256, 1))\n",
    "    \n",
    "    f = 16\n",
    "    layers = []\n",
    "    net = inputs\n",
    "  \n",
    "    for i in range(0, 6):\n",
    "        net = Conv2D(f, 3, activation='relu', padding='same') (net)\n",
    "        net = Conv2D(f, 3, activation='relu', padding='same') (net)\n",
    "        layers.append(net)\n",
    "        net = MaxPooling2D((2, 2), strides=(2, 2)) (net)\n",
    "        f = f*2\n",
    "        #512\n",
    "    ff2 = 256\n",
    "  \n",
    "    #bottleneck \n",
    "    j = len(layers) - 1\n",
    "    net = Conv2D(f, 3, activation='relu', padding='same') (net)\n",
    "    net = Conv2D(f, 3, activation='relu', padding='same') (net)\n",
    "    net = Conv2DTranspose(ff2, 2, strides=(2, 2), padding='same') (net)\n",
    "    net = Concatenate(axis=3)([net, layers[j]])\n",
    "    j = j -1 \n",
    "  \n",
    "    #upsampling \n",
    "    for i in range(0, 5):\n",
    "        ff2 = ff2//2\n",
    "        f = f // 2 \n",
    "        net = Conv2D(f, 3, activation='relu', padding='same') (net)\n",
    "        net = Conv2D(f, 3, activation='relu', padding='same') (net)\n",
    "        print(net.shape)\n",
    "        net = Conv2DTranspose(ff2, 2, strides=(2, 2), padding='same') (net)\n",
    "        print(net.shape)\n",
    "        net = Concatenate(axis=3)([net, layers[j]])\n",
    "        j = j -1 \n",
    "    \n",
    "  \n",
    "    #classification \n",
    "    net = Conv2D(f, 3, activation='relu', padding='same') (net)\n",
    "    net = Conv2D(f, 3, activation='relu', padding='same') (net)\n",
    "    outputs = Conv2D(2, 1, activation='sigmoid') (net)\n",
    "\n",
    "\n",
    "    model = Model(inputs=inputs, outputs=outputs)\n",
    "\n",
    "    model.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['acc', 'mse', tf.keras.metrics.MeanIoU(num_classes=2)])\n",
    "    model.summary()\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "organic-roots",
   "metadata": {},
   "outputs": [],
   "source": [
    "def training(model,x_train, y_train, x_val, y_val) :\n",
    "    history = model.fit(x_train, y_train, validation_data=(x_val, y_val), epochs=30, batch_size=16, \n",
    "                      callbacks=[ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=10, verbose=1, mode='auto', min_lr=1e-05)])\n",
    "    fig, ax = plt.subplots(3, 2, figsize=(10, 7))\n",
    "    plt.subplots_adjust(left=0.125,bottom=0.1, right=0.9, top=1.5, wspace=0.2, hspace=0.35)\n",
    "\n",
    "    \n",
    "    ax[0, 0].set_title('loss')\n",
    "    ax[0, 0].plot(history.history['loss'], 'r')\n",
    "    ax[0, 1].set_title('acc')\n",
    "    ax[0, 1].plot(history.history['acc'], 'b')\n",
    "\n",
    "    ax[1, 0].set_title('val_loss')\n",
    "    ax[1, 0].plot(history.history['val_loss'], 'r--')\n",
    "    ax[1, 1].set_title('val_acc')\n",
    "    ax[1, 1].plot(history.history['val_acc'], 'b--')\n",
    "    \n",
    "    ax[2,0].set_title('MeanIoU')\n",
    "    ax[2,0].plot(history.history['mean_io_u'], 'r')\n",
    "    ax[2,1].set_title('val_MeanIoU')\n",
    "    ax[2,1].plot(history.history['val_mean_io_u'], 'r')\n",
    "    \n",
    "\n",
    "    preds = model.predict(x_val)\n",
    "    fig, ax = plt.subplots(40, 4, figsize=(10, 100))\n",
    "    \n",
    "    temp = np.empty((256, 256, 1), dtype=np.float32)\n",
    "\n",
    "    for i in range(40):\n",
    "        ax[i, 0].imshow(x_val[i].squeeze(), cmap='gray')\n",
    "        ax[i, 0].title.set_text(str(i))\n",
    "    \n",
    "        y_val_0 = y_val[...,0]\n",
    "        ax[i, 1].imshow(y_val_0[i].squeeze(), cmap='gray')\n",
    "    \n",
    "        predict_0 = preds[...,0]\n",
    "        ax[i, 2].imshow(predict_0[i].squeeze(), cmap='gray')\n",
    "    \n",
    "        temp = x_val[i]\n",
    "        pred_sum = predict_0[i][predict_0[i] > 0]\n",
    "        pred_mean = np.mean(predict_0)\n",
    "        if(np.min(temp) >= 0) :\n",
    "            temp[predict_0[i] < 0.5] = 0\n",
    "        else :\n",
    "            temp[predict_0[i] < 0.5] = -2048\n",
    "        ax[i, 3].imshow(temp.squeeze(), cmap='gray')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "indonesian-holocaust",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Image_Segmentation():\n",
    "    x_train, y_train, x_val, y_val = get_Segmentation_data()\n",
    "    model = VGG16_Unet(x_train, y_train, x_val, y_val)\n",
    "    history = training(model,x_train, y_train, x_val, y_val)\n",
    "    \n",
    "    return model, history\n",
    "\n",
    "def get_Detection_data():\n",
    "    x_train, y_train, x_val, y_val = get_mask_data()\n",
    "    model = U_net(x_train, y_train, x_val, y_val)\n",
    "    history = training(model,x_train, y_train, x_val, y_val)\n",
    "    \n",
    "    return model, history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "appropriate-florida",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "finnish-portable",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "polished-production",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
